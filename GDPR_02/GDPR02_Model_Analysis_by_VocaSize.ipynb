{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GDPR02_Model_Analysis_by_VocaSize.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **GD04. Vocabulary Size에 따른 다중분류 모델 성능 비교 (feat. 로이터)**"
      ],
      "metadata": {
        "id": "DvQmr66SrnQO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INDEX**\n",
        "\n",
        "00. 사용할 모듈 가져오기\n",
        "\n",
        "01. 데이터 가져오기\n",
        "\n",
        "02. EDA 및 전처리\n",
        "\n",
        "03. 벡터화하기\n",
        "\n",
        "04. 모델 테스트\n",
        "\n",
        "05. 딥러닝 모델과 비교\n",
        "\n",
        "06. 회고"
      ],
      "metadata": {
        "id": "0BEHd68N3j9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **00. 사용할 모듈 가져오기**"
      ],
      "metadata": {
        "id": "1Jsqkqk4vnzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "\n",
        "from tensorflow.keras.datasets import reuters\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(np.__version__)\n",
        "print(pd.__version__)\n",
        "print(tf.__version__)\n",
        "print(sns.__version__)\n",
        "print(sklearn.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2GzBOSFv5CS",
        "outputId": "701c7980-5c8c-4715-c8aa-6e60031c09da"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.21.6\n",
            "1.3.5\n",
            "2.8.2\n",
            "0.11.2\n",
            "1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "vA1OFVrcwMij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **01. 데이터 가져오기**\n",
        "\n",
        "- 텐서플로우에서 제공하는 로이터 뉴스 데이터셋을 사용합니다."
      ],
      "metadata": {
        "id": "Zo7R7Q7fwauZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_5k = 5000\n",
        "words_10k = 10000\n",
        "words_none = None\n",
        "\n",
        "## 분할 비율은 전부 8:2\n",
        "# num_words = 5k\n",
        "(x_train5k, y_train5k), (x_test5k, y_test5k) = reuters.load_data(num_words=words_5k, test_split=0.2)\n",
        "\n",
        "# num_words = 10k\n",
        "(x_train10k, y_train10k), (x_test10k, y_test10k) = reuters.load_data(num_words=words_10k, test_split=0.2)\n",
        "\n",
        "# num_words = None\n",
        "(x_train_none, y_train_none), (x_test_none, y_test_none) = reuters.load_data(num_words=words_none, test_split=0.2)\n",
        "\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UjyS96uwcXw",
        "outputId": "3aee7188-9fba-4d00-d07f-e4a0e94dbfa7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n",
            "2121728/2110848 [==============================] - 0s 0us/step\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 개수는 동일, num_words만 변동\n",
        "print(\"10k 훈련 데이터:\", len(x_train10k))\n",
        "print(\"10k 테스트 데이터:\", len(x_test10k))\n",
        "\n",
        "print(\"5k 훈련 데이터:\", len(x_train5k))\n",
        "print(\"5k 테스트 데이터:\", len(x_test5k))\n",
        "\n",
        "print(\"None 훈련 데이터:\", len(x_train_none))\n",
        "print(\"None 테스트 데이터:\", len(x_test_none))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pUSIsciyOBV",
        "outputId": "9f946456-de15-4428-d384-0cdc40bba390"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10k 훈련 데이터: 8982\n",
            "10k 테스트 데이터: 2246\n",
            "5k 훈련 데이터: 8982\n",
            "5k 테스트 데이터: 2246\n",
            "None 훈련 데이터: 8982\n",
            "None 테스트 데이터: 2246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Wkt-K0yl0D8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **02. EDA 및 전처리**"
      ],
      "metadata": {
        "id": "8z-T-3Oy0S7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(x_train10k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrf4DZSJyji9",
        "outputId": "bdfaa0ae-a722-44d3-e7ed-427d93e24489"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train10k[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh3QvcSQyo5z",
        "outputId": "1f016e15-dada-4c67-8b7e-e6c2b370f3e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train10k[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gsr2eSrZywar",
        "outputId": "4dad881d-74f3-4bdc-87bc-5596fcf65e68"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "레이블과 데이터 모두 인코딩되어 있습니다."
      ],
      "metadata": {
        "id": "aTnW-y12z4Fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min(y_train10k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWoDYONB0Jlq",
        "outputId": "024743a7-9613-4555-fdef-069c6eaa37b4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = max(y_train10k)+1\n",
        "print(\"클래스의 수:\", num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkOvkvz4z_sY",
        "outputId": "4b9da6a4-bfb6-4d28-8f9c-471496bf0a27"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클래스의 수: 46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 길이 분포\n",
        "print(\"훈련 데이터의 최대 길이: {}\".format(max(len(row) for row in x_train10k)))\n",
        "print(\"훈련 데이터의 평균 길이: {}\".format(sum(map(len, x_train10k))/len(x_train10k)))\n",
        "\n",
        "plt.hist([len(s) for s in x_train10k], bins=50)\n",
        "plt.xlabel(\"샘플 길이\")\n",
        "plt.ylabel(\"샘플 개수\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "XehB5SBN0YnI",
        "outputId": "b2cd71ba-4c8c-4829-a257-ecb9338cc5fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 최대 길이: 2376\n",
            "훈련 데이터의 평균 길이: 145.5398574927633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49368 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 54540 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44600 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 51060 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 44060 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 49688 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49368 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 54540 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44600 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 51060 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 44060 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 49688 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "평균 길이에 비해 최대 길이가 깁니다.\n",
        "\n",
        "클래스 분포를 확인해보겠습니다."
      ],
      "metadata": {
        "id": "qC4PRURd1NI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axe = plt.subplots(ncols=1)\n",
        "fig.set_size_inches(11, 5)\n",
        "sns.countplot(x=y_train10k)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "8lPcRomC1dM8",
        "outputId": "fbca11c3-256a-49d9-b892-a2aac2e7eb91"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 792x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_elements, counts_elements = np.unique(y_train10k, return_counts=True)\n",
        "print(\"각 클래스 빈도수\")\n",
        "print(np.array((unique_elements, counts_elements)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfCj2jSl1nl8",
        "outputId": "2c0a6e6a-e6e8-4d5a-968c-d453ad1dc4db"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 클래스 빈도수\n",
            "[[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
            "    14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
            "    28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
            "    42   43   44   45]\n",
            " [  55  432   74 3159 1949   17   48   16  139  101  124  390   49  172\n",
            "    26   20  444   39   66  549  269  100   15   41   62   92   24   15\n",
            "    48   19   45   39   32   11   50   10   49   19   19   24   36   30\n",
            "    13   21   12   18]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "물론 결측치가 전부 다 잘 처리된 데이터셋이지만, 일단 혹시 모르니 확인해보겠습니다."
      ],
      "metadata": {
        "id": "rwH4bbx114fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = pd.DataFrame(columns=['x_train', 'y_train'])\n",
        "test_set = pd.DataFrame(columns=['x_test', 'y_test'])\n",
        "\n",
        "train_set['x_train'] = x_train10k\n",
        "train_set['y_train'] = y_train10k\n",
        "test_set['x_test'] = x_test10k\n",
        "test_set['y_test'] = y_test10k\n",
        "\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds65wqB-2myL",
        "outputId": "7547a514-4a4c-4933-96e2-2032c1155644"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HmC6NF33xkl",
        "outputId": "6f31238d-a748-4acf-c227-bb57e8a84bc5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x_train    0\n",
              "y_train    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJX9ttQM4E17",
        "outputId": "49c01c5f-85df-49f0-ef13-412406f981e8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x_test    0\n",
              "y_test    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결측치는 없습니다."
      ],
      "metadata": {
        "id": "GuWU3m5p4RfK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "s92J8fxI4epz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **03. 벡터화하기**\n",
        "\n",
        "DTM 기반 전처리를 하려면 다시 디코딩을 해주어야 합니다."
      ],
      "metadata": {
        "id": "acY8GT5w4fPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
      ],
      "metadata": {
        "id": "Md4lzP1D4hip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea44c863-6eab-453b-b16b-0794b495faec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n",
            "565248/550378 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# index +3\n",
        "index_to_word = {index + 3 : word for word, index in word_index.items()}\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8ADf07NgHfj",
        "outputId": "57dd29f2-9c83-4bb5-a312-8c06cc721486"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0=<pad>, 1=<sos>, 2=<unk>\n",
        "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "  index_to_word[index]=token\n",
        "\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxaFjOKZcEHW",
        "outputId": "432ec8a7-d27b-44ad-bc49-3a80261aaf20"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(' '.join([index_to_word[index] for index in x_train10k[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYNmsWsBcUsN",
        "outputId": "5e62b64f-52c7-46c3-ea32-b44fd4b90676"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 데이터 변환\n",
        "decoded_10k, decoded_5k, decoded_none = [], [], []\n",
        "test10k, test5k, test_none = [], [], []\n",
        "\n",
        "## train\n",
        "# 10k\n",
        "for i in range(len(x_train10k)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_train10k[i]])\n",
        "    decoded_10k.append(t)\n",
        "x_train10k = decoded_10k\n",
        "\n",
        "# 5k\n",
        "for i in range(len(x_train5k)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_train5k[i]])\n",
        "    decoded_5k.append(t)\n",
        "x_train5k = decoded_5k\n",
        "\n",
        "# none\n",
        "for i in range(len(x_train_none)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_train_none[i]])\n",
        "    decoded_none.append(t)\n",
        "x_train_none = decoded_none\n",
        "\n",
        "## test\n",
        "# 10k\n",
        "for i in range(len(x_test10k)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_test10k[i]])\n",
        "    test10k.append(t)\n",
        "x_test10k = test10k\n",
        "\n",
        "# 5k\n",
        "for i in range(len(x_test5k)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_test5k[i]])\n",
        "    test5k.append(t)\n",
        "x_test5k = test5k\n",
        "\n",
        "# none\n",
        "for i in range(len(x_test_none)):\n",
        "    t = ' '.join([index_to_word[index] for index in x_test_none[i]])\n",
        "    test_none.append(t)\n",
        "x_test_none = test_none\n",
        "\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p730SurZmcTF",
        "outputId": "fc8eb6f6-8905-4d92-cd6b-3515270f38b0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3-1. train data 변환**"
      ],
      "metadata": {
        "id": "aFMHX2nLpmdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## DTM 생성\n",
        "# 5k\n",
        "dtmvector = CountVectorizer()\n",
        "x_train_dtm5k = dtmvector.fit_transform(x_train5k)\n",
        "print(\"5k: {}\".format(x_train_dtm5k.shape))\n",
        "\n",
        "# 10k\n",
        "dtmvector2 = CountVectorizer()\n",
        "x_train_dtm10k = dtmvector2.fit_transform(x_train10k)\n",
        "print(\"10k: {}\".format(x_train_dtm10k.shape))\n",
        "\n",
        "# none\n",
        "dtmvector3 = CountVectorizer()\n",
        "x_train_dtm_none = dtmvector3.fit_transform(x_train_none)\n",
        "print(\"None: {}\".format(x_train_dtm_none.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_2pelPGnhd3",
        "outputId": "81298d4f-8c95-4467-a060-565158b028ae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5k: (8982, 4867)\n",
            "10k: (8982, 9670)\n",
            "None: (8982, 26506)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TF-IDF 생성\n",
        "# 5k\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "tfidfv_5k = tfidf_transformer.fit_transform(x_train_dtm5k)\n",
        "print(tfidfv_5k.shape)\n",
        "\n",
        "# 10k\n",
        "tfidf_transformer2 = TfidfTransformer()\n",
        "tfidfv_10k = tfidf_transformer2.fit_transform(x_train_dtm10k)\n",
        "print(tfidfv_10k.shape)\n",
        "\n",
        "# none\n",
        "tfidf_transformer3 = TfidfTransformer()\n",
        "tfidfv_none = tfidf_transformer3.fit_transform(x_train_dtm_none)\n",
        "print(tfidfv_none.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7aQSaYnoF69",
        "outputId": "e3bbb511-3bf5-4d57-b128-bf03049537d9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8982, 4867)\n",
            "(8982, 9670)\n",
            "(8982, 26506)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3-2. test data 변환**"
      ],
      "metadata": {
        "id": "YSAyxalIpqOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## DTM / TF-IDF 생성\n",
        "# 5k\n",
        "x_test_dtm5k = dtmvector.transform(x_test5k)\n",
        "tfidfv_5k_test = tfidf_transformer.transform(x_test_dtm5k)\n",
        "print(\"5k: {}\".format(tfidfv_5k_test.shape))\n",
        "\n",
        "# 10k\n",
        "x_test_dtm10k = dtmvector2.transform(x_test10k)\n",
        "tfidfv_10k_test = tfidf_transformer2.transform(x_test_dtm10k)\n",
        "print(\"10k: {}\".format(tfidfv_10k_test.shape))\n",
        "\n",
        "# none\n",
        "x_test_dtm_none = dtmvector3.transform(x_test_none)\n",
        "tfidfv_none_test = tfidf_transformer3.transform(x_test_dtm_none)\n",
        "print(\"None: {}\".format(tfidfv_none_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19T_uekmptGZ",
        "outputId": "52fa9168-2d0f-4ae8-a2ef-61e370c37681"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5k: (2246, 4867)\n",
            "10k: (2246, 9670)\n",
            "None: (2246, 26506)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "jbNOZb0cnLne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **04. 모델 테스트**"
      ],
      "metadata": {
        "id": "AnE0YHXwneCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4-1. 함수 선언**"
      ],
      "metadata": {
        "id": "DvmcihFwng9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델별로 하이퍼파라미터 튜닝 없이 기본 fit 함수 활용\n",
        "def default_model_testing(train_data, y_train, x_test, y_test, name):\n",
        "    model = name()\n",
        "    model.fit(train_data, y_train)\n",
        "    predicted = model.predict(x_test)\n",
        "    print(name, \"accuracy: {}\".format(accuracy_score(y_test, predicted)))\n",
        "\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NXfcdoLFvSu",
        "outputId": "f2276042-2739-42a0-83ff-f4f016e3c15b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델별로 하이퍼파라미터 튜닝\n",
        "random_state = 2022\n",
        "\n",
        "def tuned_model_testing(train_data, y_train, x_test, y_test):\n",
        "\n",
        "    # 01. 나이브 베이즈\n",
        "    model = MultinomialNB()\n",
        "    model.fit(train_data, y_train)\n",
        "    predicted = model.predict(x_test)\n",
        "    print(\"나이브 베이즈 ACC: {}\".format(accuracy_score(y_test, predicted)))\n",
        "    \n",
        "    # 02. Complement NB\n",
        "    model = ComplementNB()\n",
        "    model.fit(train_data, y_train)\n",
        "    predicted = model.predict(x_test)\n",
        "    print(\"Complemnet NB ACC: {}\".format(accuracy_score(y_test, predicted)))\n",
        "\n",
        "    # 03. Logistic Regression\n",
        "    model = LogisticRegression(C=10000, penalty='l2')\n",
        "    model.fit(train_data, y_train)\n",
        "    predicted = model.predict(x_test)\n",
        "    print(\"Logistic Regression ACC: {}\".format(accuracy_score(y_test, predicted)))\n",
        "\n",
        "    # 04. SGD Classifier\n",
        "    model = SGDClassifier()\n",
        "    model.fit(train_data, y_train)\n",
        "    predicted = model.predict(x_test)\n",
        "    print(\"SGD Classifier ACC: {}\".format(accuracy_score(y_test, predicted)))\n",
        "\n",
        "    # 05. Decision Tree\n",
        "    model = DecisionTreeClassifier(max_depth=10, random_state=random_state)\n",
        "    model.fit(train_data, y_train)\n",
        "    predicted = model.predict(x_test)\n",
        "    print(\"Decision Tree ACC: {}\".format(accuracy_score(y_test, predicted)))\n",
        "\n",
        "    # 06. Random Forest\n",
        "    model = RandomForestClassifier(n_estimators=5, random_state=random_state)\n",
        "    model.fit(train_data, y_train)\n",
        "    predicted = model.predict(x_test)\n",
        "    print(\"Random Forest ACC: {}\".format(accuracy_score(y_test, predicted)))\n",
        "    \n",
        "    # 07. GradientBoosting\n",
        "    model = GradientBoostingClassifier(random_state=random_state)\n",
        "    model.fit(train_data, y_train)\n",
        "    predicted = model.predict(x_test)\n",
        "    print(\"GradientBoosting ACC: {}\".format(accuracy_score(y_test, predicted)))\n",
        "\n",
        "    # 08. LinearSVC\n",
        "    # LinearSVC는 L2 Reg, c=1.0가 디폴트\n",
        "    model = LinearSVC()\n",
        "    model.fit(train_data, y_train)\n",
        "    predicted = model.predict(x_test)\n",
        "    print(\"LinearSVC ACC: {}\".format(accuracy_score(y_test, predicted)))\n",
        "\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvNTppPDLXYU",
        "outputId": "181bbedc-a077-4e24-8efc-0f79d13aaf0b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4-2 훈련 & 평가**"
      ],
      "metadata": {
        "id": "4tFSpIOxYrBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4-2-1. 디폴트 함수를 사용할 경우**"
      ],
      "metadata": {
        "id": "vBpMMjzbaKl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10k\n",
        "model_list = [MultinomialNB, ComplementNB,\n",
        "              LogisticRegression, SGDClassifier,\n",
        "              DecisionTreeClassifier, RandomForestClassifier,\n",
        "              GradientBoostingClassifier, LinearSVC]\n",
        "\n",
        "for names in model_list:\n",
        "    default_model_testing(tfidfv_10k, y_train10k, tfidfv_10k_test, y_test10k, names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zodQby0kGlkt",
        "outputId": "788a73a5-e4d2-4f96-ad88-32959dab387f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.naive_bayes.MultinomialNB'> accuracy: 0.6567230632235085\n",
            "<class 'sklearn.naive_bayes.ComplementNB'> accuracy: 0.7707034728406055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.linear_model._logistic.LogisticRegression'> accuracy: 0.7951914514692787\n",
            "<class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'> accuracy: 0.8450578806767587\n",
            "<class 'sklearn.tree._classes.DecisionTreeClassifier'> accuracy: 0.6932324131789849\n",
            "<class 'sklearn.ensemble._forest.RandomForestClassifier'> accuracy: 0.7537845057880677\n",
            "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'> accuracy: 0.7662511130899377\n",
            "<class 'sklearn.svm._classes.LinearSVC'> accuracy: 0.8299198575244879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5k\n",
        "for names in model_list:\n",
        "    default_model_testing(tfidfv_5k, y_train5k, tfidfv_5k_test, y_test5k, names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3h4GSleYZ7J",
        "outputId": "ed69d679-8362-41e0-e776-85d3e96b5c5f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.naive_bayes.MultinomialNB'> accuracy: 0.6731967943009796\n",
            "<class 'sklearn.naive_bayes.ComplementNB'> accuracy: 0.7707034728406055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.linear_model._logistic.LogisticRegression'> accuracy: 0.7978628673196795\n",
            "<class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'> accuracy: 0.8423864648263579\n",
            "<class 'sklearn.tree._classes.DecisionTreeClassifier'> accuracy: 0.6959038290293855\n",
            "<class 'sklearn.ensemble._forest.RandomForestClassifier'> accuracy: 0.7658058771148709\n",
            "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'> accuracy: 0.7707034728406055\n",
            "<class 'sklearn.svm._classes.LinearSVC'> accuracy: 0.8290293855743545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# None\n",
        "for names in model_list:\n",
        "    default_model_testing(tfidfv_none, y_train_none, tfidfv_none_test, y_test_none, names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xs5tVHV_YhpP",
        "outputId": "e7a1ed90-15d0-4950-b7b1-981cfd48bcf8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.naive_bayes.MultinomialNB'> accuracy: 0.5997328584149599\n",
            "<class 'sklearn.naive_bayes.ComplementNB'> accuracy: 0.7649154051647373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.linear_model._logistic.LogisticRegression'> accuracy: 0.7920747996438112\n",
            "<class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'> accuracy: 0.8459483526268923\n",
            "<class 'sklearn.tree._classes.DecisionTreeClassifier'> accuracy: 0.6994657168299199\n",
            "<class 'sklearn.ensemble._forest.RandomForestClassifier'> accuracy: 0.744879786286732\n",
            "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'> accuracy: 0.7724844167408726\n",
            "<class 'sklearn.svm._classes.LinearSVC'> accuracy: 0.8294746215494212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과값을 표로 나타내면 다음과 같습니다.\n",
        "\n",
        "num_words | Multinomial NB | Complement NB | Logistic Regression | Stochastic Gradient Descent | Decision Tree | Random Forest | Gradient Boosting | Linear SVC\n",
        ":--|--:|--:|--:|--:|--:|--:|--:|--:\n",
        "**5k** | 67.32 | 77.07 | 79.79 | 84.24 | 69.59 | 76.58 | 77.07 | 82.90\n",
        "**10k** | 65.67 | 77.07 | 79.52 | 84.51 | 69.32 | 75.38 | 76.63 | 82.99\n",
        "**None** | 59.97 | 76.49 | 79.21 | 84.60 | 69.95 | 74.49 | 77.25 | 82.95\n"
      ],
      "metadata": {
        "id": "6jDUA6AJcDSs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델에 따라 num_words의 크기에 따른 결과가 다릅니다. 일부는 num_words가 작을 수록 성능이 향상되고, 다른 것들은 그 반대입니다.\n",
        "\n",
        "일관적으로 성능이 줄어드는 특정 모델들의 경우 베이지안 기반이라는 공통점이 있습니다. 베이지안 기반 모델의 특징은 각각의 피처를 동등하게 보는 경험적 확률을 사용하기 때문에 참고하는 데이터의 개수에 큰 영향을 받는다는 것입니다. 즉, 참고할 피처 수가 늘어날 수록 모델의 추론력이 하락한다는 단점이 있습니다.\n",
        "\n",
        "이 경우, num_words가 참고하는 데이터의 개수에 해당합니다.\n",
        "\n",
        "실제로 Multinomial/Complement NB 모델의 경우 일관적으로 성능이 줄어듭니다. 반면에 Gradient Boosting과 Linear SVC의 경우에는 성능의 변화가 일관적이지 않습니다. 이 경우에는 결과의 신뢰도가 다소 저하되므로, 데이터 크기에 따른 일관적인 성능 변화를 보여준 모델들(MNB, CNB, LR, RF)을 기준으로 적합한 num_words를 선정하겠습니다.\n",
        "\n",
        "따라서 **적합한 num_words = 5k**입니다."
      ],
      "metadata": {
        "id": "ryutjM7hcQ16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4-2-2. 하이퍼 파라미터 튜닝했을 경우**"
      ],
      "metadata": {
        "id": "2bh4cfnZaOQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5k\n",
        "tuned_model_testing(tfidfv_5k, y_train5k, tfidfv_5k_test, y_test5k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spgin7rtaYoV",
        "outputId": "bb708aea-fcdd-4644-af8c-2eea4aafe24c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "나이브 베이즈 ACC: 0.6731967943009796\n",
            "Complemnet NB ACC: 0.7707034728406055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression ACC: 0.8058771148708815\n",
            "SGD Classifier ACC: 0.8410507569011576\n",
            "Decision Tree ACC: 0.6179875333926982\n",
            "Random Forest ACC: 0.7008014247551202\n",
            "GradientBoosting ACC: 0.7671415850400712\n",
            "LinearSVC ACC: 0.8290293855743545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4-3.3 Soft Voting**\n",
        "\n",
        "status | Multinomial NB | Complement NB | Logistic Regression | Stochastic Gradient Descent | Decision Tree | Random Forest | Gradient Boosting | Linear SVC\n",
        ":--|--:|--:|--:|--:|--:|--:|--:|--:\n",
        "**Before** (not tuned) | 67.32 | 77.07 | 79.79 | **84.24** | **69.59** | **76.58** | **77.07** | 82.90\n",
        "**After** (tuned) | 67.32 | 77.07 | **80.59** | 84.11 | 61.80 | 70.08 | 76.71 | 82.90\n",
        "**Is Tuned?** | N | N | Y | N | Y | Y | Y | N\n",
        "\n"
      ],
      "metadata": {
        "id": "siSVpqx-lHAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과는 위와 같습니다.\n",
        "\n",
        "성능의 우열은 크게 바뀌지 않습니다만 SGD의 경우 별도의 하이퍼 파라미터 지정을 하지 않았음에도 모델의 특성상 (확률 이슈로 인해) 성능이 조금 차이나는 것을 확인할 수 있습니다.\n",
        "\n",
        "하이퍼 파라미터 튜닝을 해준 모델들(DT, RF, GB, LR) 중 로지스틱 회귀를 제외한 나머지는 오히려 성능이 저하되었습니다. 노드에서 제공하는 하이퍼 파라미터 옵션이 최적화된 옵션이 아니라는 의미일 수 있겠네요. (사실 Logistic Regression에서 iteration 경고가 나타나는 것을 보면 최적화된 옵션이 아니라는 점을 미리 알 수 있긴 합니다.)\n",
        "\n",
        "이제 Top3 모델 (SGD, Linear SVC, Logistic Regression)을 골라 보팅을 하겠습니다. 데이터가 불균형하므로 f1 score를 사용할 수도 있겠지만, 뉴스 카테고리 분류 문제는 어찌됐든 정답을 맞추기만 하면 되므로 여기서는 accuracy를 기준으로 평가합니다."
      ],
      "metadata": {
        "id": "2K72IX5R2Jar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hard voting\n",
        "def voting_test(train_data, y_train, x_test, y_test):\n",
        "    voting_classifier = VotingClassifier(estimators=[('SGD', SGDClassifier(random_state=random_state)),\n",
        "                                                     ('LSVC', LinearSVC(random_state=random_state)),\n",
        "                                                     ('LR', LogisticRegression(random_state=random_state, C=10000, penalty='l2'))],\n",
        "                                         \n",
        "                                         # SGDClassifier의 디폴트 loss함수가 hinge이기 때문에 바로 soft voting이 되지 않습니다.\n",
        "                                         # 또한 LinearSVC는 클래스 확률값을 제공하지 않으므로 probability=True 옵션을 주어야 합니다.\n",
        "                                         # 여기서는 간단하게 hard voting을 사용합니다.\n",
        "\n",
        "                                         voting='hard', n_jobs=-1)\n",
        "\n",
        "    voting_classifier.fit(train_data, y_train)\n",
        "    predicted = voting_classifier.predict(x_test)\n",
        "    print(\"Voting ACC: {}\".format(accuracy_score(y_test, predicted)))\n",
        "\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBwJAfdIuWA3",
        "outputId": "56e25cd0-2472-4c23-fe6d-727b7df31a38"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voting_test(tfidfv_5k, y_train5k, tfidfv_5k_test, y_test5k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dPWi_8Px5l4",
        "outputId": "d3d0f1d2-4f4f-4b3a-ae1a-6df58e8305a6"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting ACC: 0.8290293855743545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "머신러닝 모델의 최종 ACC 결과값은 0.8290 입니다."
      ],
      "metadata": {
        "id": "yIplciuP1pz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **05. 딥러닝 모델과 비교**"
      ],
      "metadata": {
        "id": "I3x92AsifLBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5-1. Simple RNN**\n",
        "\n",
        "TF-IDF 모델은 기본적으로 문서가 포함하는 단어들의 빈도를 기반으로 삼습니다.\n",
        "\n",
        "하지만 그 순서는 알기 어렵기 때문에 데이터를 순서대로 넣어줘야 할 필요가 있습니다.\n",
        "\n",
        "따라서 시퀀스 처리에 적합한 딥러닝 모델을 사용합니다."
      ],
      "metadata": {
        "id": "YaxTKyj-fPrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# simple RNN\n",
        "\n",
        "vocab_size = 20000\n",
        "word_vector_dim = 128  \n",
        "\n",
        "model_LSTM = keras.Sequential()\n",
        "model_LSTM.add(keras.layers.Embedding(vocab_size, word_vector_dim))\n",
        "model_LSTM.add(keras.layers.LSTM(64))\n",
        "model_LSTM.add(keras.layers.Dense(num_classes, activation='softmax'))  \n",
        "\n",
        "model_LSTM.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmxEJFvrfRzE",
        "outputId": "33d382bc-22d5-4b88-f3f7-fe2b1481cd23"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, None, 128)         2560000   \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 46)                2990      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,612,398\n",
            "Trainable params: 2,612,398\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5k\n",
        "tfidfv_5k.shape, y_train5k.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r62ZVnQsfwp-",
        "outputId": "df300370-1def-4748-8247-a1b390b93d15"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8982, 4867), (8982,))"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seq data 형태로 변환\n",
        "tfidfv_5k_densed = tfidfv_5k.toarray()\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTuvNNSDkAoQ",
        "outputId": "beb81da4-1d68-41b8-9978-fa7f5b078ea6"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "\n",
        "model_LSTM.compile(optimizer='adam',\n",
        "                   loss='sparse_categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "            \n",
        "epochs=20\n",
        "batch_size=64\n",
        "\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwmXP8-ViTqD",
        "outputId": "f081418e-1d74-49aa-ba8c-16d37449b208"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "history_LSTM = model_LSTM.fit(tfidfv_5k_densed,\n",
        "                              y_train5k,\n",
        "                              epochs=epochs,\n",
        "                              validation_split=0.2,\n",
        "                              batch_size=batch_size,\n",
        "                              callbacks=es,\n",
        "                              verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahbUuBngjntA",
        "outputId": "bcf1cb09-0cd4-452f-d06c-ce44a3176949"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "113/113 [==============================] - 27s 227ms/step - loss: 2.6243 - accuracy: 0.3166 - val_loss: 2.4064 - val_accuracy: 0.3450\n",
            "Epoch 2/20\n",
            "113/113 [==============================] - 24s 213ms/step - loss: 2.4104 - accuracy: 0.3534 - val_loss: 2.4117 - val_accuracy: 0.3450\n",
            "Epoch 3/20\n",
            "113/113 [==============================] - 25s 218ms/step - loss: 2.4106 - accuracy: 0.3534 - val_loss: 2.4119 - val_accuracy: 0.3450\n",
            "Epoch 4/20\n",
            "113/113 [==============================] - 24s 215ms/step - loss: 2.4094 - accuracy: 0.3534 - val_loss: 2.4088 - val_accuracy: 0.3450\n",
            "Epoch 5/20\n",
            "113/113 [==============================] - 26s 227ms/step - loss: 2.4111 - accuracy: 0.3534 - val_loss: 2.4075 - val_accuracy: 0.3450\n",
            "Epoch 5: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능이 영 시원찮아 보입니다.\n",
        "\n",
        "아무래도 input으로 사용하는 데이터 수가 적어서 충분히 학습하지 못하는 것 같습니다.\n",
        "\n",
        "일단 한번 테스트해보겠습니다."
      ],
      "metadata": {
        "id": "NnU3MFh3lwEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfv_5k_test_densed = tfidfv_5k_test.toarray()\n",
        "rnn_result = model_LSTM.evaluate(tfidfv_5k_test_densed, y_test5k, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3e4iPLjm4Dr",
        "outputId": "c3f4e7f7-1b9b-4fca-dc54-e5a0f9d614d7"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 - 6s - loss: 2.4180 - accuracy: 0.3620 - 6s/epoch - 78ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델의 정확도는 약 36.2%입니다."
      ],
      "metadata": {
        "id": "uBE2MyoInedK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "pT1ununGnzD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5-2. 모델 개선**\n",
        "\n",
        "layer 수를 늘리고 drop out을 걸어서 조금 더 개선해 보겠습니다."
      ],
      "metadata": {
        "id": "Ep53h_W-n0Oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# more layers\n",
        "# use drop out\n",
        "\n",
        "model_LSTM2 = keras.Sequential()\n",
        "model_LSTM2.add(keras.layers.Dense(128, activation='relu', input_shape=(tfidfv_5k_densed.shape[1],)))\n",
        "model_LSTM2.add(keras.layers.Dropout(0.2))  \n",
        "model_LSTM2.add(keras.layers.Dense(128, activation='relu'))\n",
        "model_LSTM2.add(keras.layers.Dense(256, activation='relu')) \n",
        "model_LSTM2.add(keras.layers.Dense(512, activation='relu'))  \n",
        "model_LSTM2.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model_LSTM2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ifsjbnryn2ZC",
        "outputId": "ad5fe141-77fe-494e-8ffc-0c39135fb224"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 128)               623104    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 46)                23598     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 827,822\n",
            "Trainable params: 827,822\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_LSTM2.compile(optimizer='adam',\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "agzQNyT_pf-b"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_LSTM2 = model_LSTM2.fit(tfidfv_5k_densed,\n",
        "                               y_train5k,\n",
        "                               epochs=epochs,\n",
        "                               validation_split=0.2,\n",
        "                               batch_size=batch_size,\n",
        "                               callbacks=es,\n",
        "                               verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urrgINK4qRAG",
        "outputId": "7762a89d-a619-4748-dde9-473bceb4c3d8"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.9574 - accuracy: 0.5079 - val_loss: 1.3869 - val_accuracy: 0.6784\n",
            "Epoch 2/20\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1091 - accuracy: 0.7240 - val_loss: 1.0623 - val_accuracy: 0.7551\n",
            "Epoch 3/20\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.7200 - accuracy: 0.8189 - val_loss: 0.9911 - val_accuracy: 0.7780\n",
            "Epoch 4/20\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.8697 - val_loss: 1.0365 - val_accuracy: 0.7707\n",
            "Epoch 5/20\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.3504 - accuracy: 0.9038 - val_loss: 1.1099 - val_accuracy: 0.7741\n",
            "Epoch 6/20\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2717 - accuracy: 0.9272 - val_loss: 1.1311 - val_accuracy: 0.7902\n",
            "Epoch 7/20\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.2133 - accuracy: 0.9393 - val_loss: 1.1592 - val_accuracy: 0.7813\n",
            "Epoch 7: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "rnn_result2 = model_LSTM2.evaluate(tfidfv_5k_test_densed, y_test5k, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW0MYBDSqdZF",
        "outputId": "b6966fd7-815f-4d16-afa5-bedba23e35e3"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 - 0s - loss: 1.2215 - accuracy: 0.7760 - 162ms/epoch - 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정확도가 기존보다 2배 넘게 상승했습니다.\n",
        "\n",
        "한번 F1 score도 살펴보겠습니다."
      ],
      "metadata": {
        "id": "I-4HYPvcqiXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test5k, model_LSTM2.predict(tfidfv_5k_test_densed).argmax(axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmBceDap19mH",
        "outputId": "77e80531-cd34-4f86-f897-01ddadece819"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.67      0.48        12\n",
            "           1       0.73      0.70      0.72       105\n",
            "           2       0.43      0.65      0.52        20\n",
            "           3       0.93      0.92      0.93       813\n",
            "           4       0.83      0.88      0.85       474\n",
            "           5       0.09      0.20      0.13         5\n",
            "           6       0.69      0.79      0.73        14\n",
            "           7       1.00      0.33      0.50         3\n",
            "           8       0.49      0.66      0.56        38\n",
            "           9       0.66      0.76      0.70        25\n",
            "          10       0.92      0.73      0.81        30\n",
            "          11       0.62      0.70      0.66        83\n",
            "          12       0.33      0.15      0.21        13\n",
            "          13       0.62      0.65      0.63        37\n",
            "          14       0.25      0.50      0.33         2\n",
            "          15       0.33      0.11      0.17         9\n",
            "          16       0.68      0.74      0.71        99\n",
            "          17       0.41      0.58      0.48        12\n",
            "          18       0.55      0.60      0.57        20\n",
            "          19       0.64      0.71      0.68       133\n",
            "          20       0.71      0.39      0.50        70\n",
            "          21       0.71      0.74      0.73        27\n",
            "          22       0.00      0.00      0.00         7\n",
            "          23       0.38      0.25      0.30        12\n",
            "          24       0.47      0.47      0.47        19\n",
            "          25       0.84      0.52      0.64        31\n",
            "          26       0.46      0.75      0.57         8\n",
            "          27       1.00      0.50      0.67         4\n",
            "          28       0.38      0.30      0.33        10\n",
            "          29       0.00      0.00      0.00         4\n",
            "          30       0.67      0.17      0.27        12\n",
            "          31       0.57      0.31      0.40        13\n",
            "          32       1.00      0.70      0.82        10\n",
            "          33       0.80      0.80      0.80         5\n",
            "          34       0.50      0.43      0.46         7\n",
            "          35       0.67      0.33      0.44         6\n",
            "          36       0.64      0.64      0.64        11\n",
            "          37       0.25      0.50      0.33         2\n",
            "          38       0.00      0.00      0.00         3\n",
            "          39       0.00      0.00      0.00         5\n",
            "          40       0.50      0.50      0.50        10\n",
            "          41       0.33      0.38      0.35         8\n",
            "          42       0.00      0.00      0.00         3\n",
            "          43       0.50      0.33      0.40         6\n",
            "          44       0.80      0.80      0.80         5\n",
            "          45       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.78      2246\n",
            "   macro avg       0.52      0.47      0.47      2246\n",
            "weighted avg       0.78      0.78      0.77      2246\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "딥러닝 모델의 최종 정확도는 **77.6%** 입니다."
      ],
      "metadata": {
        "id": "hxNJwgQT2y_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **06. 회고**\n",
        "\n",
        "- 머신러닝 모델은 딥러닝 모델에 비해 상대적으로 robust하다는 것을 볼 수 있었습니다. 실제로 딥러닝 모델의 초기 훈련 결과 약 36%의 정확도를 보였지만, 머신러닝 모델의 경우 별다른 튜닝 없는 디폴트 상태로 사용했을 때에도 최소 59%의 성능을 보여주었습니다.\n",
        "\n",
        "- 대신 딥러닝 모델은 설계에 따라 정확도가 급상승한다는 장점이 있습니다. 또한 머신러닝 모델보다 훨씬 세밀하게 모델을 조절할 수 있습니다. 머신러닝 모델의 경우 하이퍼파라미터 튜닝에 따른 성능 변화가 드라마틱할 정도로 크지는 않습니다. 따라서 정확도가 매우 중요한 분야(의료, 금융, 반도체 공정 등)에서는 머신러닝 모델보다 잘 설계된 딥러닝 모델을 사용하는 것이 더 좋다고 판단할 수 있습니다."
      ],
      "metadata": {
        "id": "6lOZ9x4Yylsh"
      }
    }
  ]
}
